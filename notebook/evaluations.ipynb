{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70a751a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.1 environment at: /workspaces/End2End_RAG/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m6 packages\u001b[0m \u001b[2min 824ms\u001b[0m\u001b[0m                                         \u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)-------------------\u001b[0m\u001b[0m     0 B/11.79 MiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)-------------------\u001b[0m\u001b[0m 14.90 KiB/11.79 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)-------------------\u001b[0m\u001b[0m 14.90 KiB/11.79 MiB         \u001b[1A\n",
      "\u001b[2mpytz                \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/497.29 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)-------------------\u001b[0m\u001b[0m 14.90 KiB/11.79 MiB         \u001b[2A\n",
      "\u001b[2mpytz                \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/497.29 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)-------------------\u001b[0m\u001b[0m 14.90 KiB/11.79 MiB         \u001b[2A\n",
      "\u001b[2mpytz                \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/497.29 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)-------------------\u001b[0m\u001b[0m 14.90 KiB/11.79 MiB         \u001b[2A\n",
      "\u001b[2mtzdata              \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/339.69 KiB\n",
      "\u001b[2mpytz                \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/497.29 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)-------------------\u001b[0m\u001b[0m 14.90 KiB/11.79 MiB         \u001b[3A\n",
      "\u001b[2mtzdata              \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/339.69 KiB\n",
      "\u001b[2mpytz                \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 14.88 KiB/497.29 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)-------------------\u001b[0m\u001b[0m 14.90 KiB/11.79 MiB         \u001b[3A\n",
      "\u001b[2mtzdata              \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.87 KiB/339.69 KiB\n",
      "\u001b[2mpytz                \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 14.88 KiB/497.29 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)-------------------\u001b[0m\u001b[0m 14.90 KiB/11.79 MiB         \u001b[3A\n",
      "\u001b[2mtzdata              \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.87 KiB/339.69 KiB\n",
      "\u001b[2mpytz                \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 14.88 KiB/497.29 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)-------------------\u001b[0m\u001b[0m 21.29 KiB/11.79 MiB         \u001b[3A\n",
      "\u001b[2mtzdata              \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.87 KiB/339.69 KiB\n",
      "\u001b[2mpytz                \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m 14.88 KiB/497.29 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)-------------------\u001b[0m\u001b[0m 26.78 KiB/11.79 MiB         \u001b[3A\n",
      "\u001b[2mtzdata              \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.87 KiB/339.69 KiB\n",
      "\u001b[2mpytz                \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 20.36 KiB/497.29 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)-------------------\u001b[0m\u001b[0m 26.78 KiB/11.79 MiB         \u001b[3A\n",
      "\u001b[2mtzdata              \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 20.36 KiB/339.69 KiB\n",
      "\u001b[2mpytz                \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 20.36 KiB/497.29 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)-------------------\u001b[0m\u001b[0m 26.78 KiB/11.79 MiB         \u001b[3A\n",
      "\u001b[2mtzdata              \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 20.36 KiB/339.69 KiB\n",
      "\u001b[2mpytz                \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 20.36 KiB/497.29 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)-------------------\u001b[0m\u001b[0m 42.78 KiB/11.79 MiB         \u001b[3A\n",
      "\u001b[2mtzdata              \u001b[0m \u001b[32m-\u001b[30m\u001b[2m-----------------------------\u001b[0m\u001b[0m 20.36 KiB/339.69 KiB\n",
      "\u001b[2mpytz                \u001b[0m \u001b[32m--\u001b[30m\u001b[2m----------------------------\u001b[0m\u001b[0m 36.36 KiB/497.29 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)-------------------\u001b[0m\u001b[0m 42.78 KiB/11.79 MiB         \u001b[3A\n",
      "\u001b[2mtzdata              \u001b[0m \u001b[32m---\u001b[30m\u001b[2m---------------------------\u001b[0m\u001b[0m 36.36 KiB/339.69 KiB\n",
      "\u001b[2mpytz                \u001b[0m \u001b[32m--\u001b[30m\u001b[2m----------------------------\u001b[0m\u001b[0m 36.36 KiB/497.29 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)-------------------\u001b[0m\u001b[0m 42.78 KiB/11.79 MiB         \u001b[3A\n",
      "\u001b[2mtzdata              \u001b[0m \u001b[32m---\u001b[30m\u001b[2m---------------------------\u001b[0m\u001b[0m 36.36 KiB/339.69 KiB\n",
      "\u001b[2mpytz                \u001b[0m \u001b[32m--\u001b[30m\u001b[2m----------------------------\u001b[0m\u001b[0m 36.36 KiB/497.29 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)-------------------\u001b[0m\u001b[0m 58.78 KiB/11.79 MiB         \u001b[3A\n",
      "\u001b[2mtzdata              \u001b[0m \u001b[32m---\u001b[30m\u001b[2m---------------------------\u001b[0m\u001b[0m 36.36 KiB/339.69 KiB\n",
      "\u001b[2mpytz                \u001b[0m \u001b[32m---\u001b[30m\u001b[2m---------------------------\u001b[0m\u001b[0m 52.36 KiB/497.29 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)-------------------\u001b[0m\u001b[0m 58.78 KiB/11.79 MiB         \u001b[3A\n",
      "\u001b[2mtzdata              \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 52.36 KiB/339.69 KiB\n",
      "\u001b[2mpytz                \u001b[0m \u001b[32m---\u001b[30m\u001b[2m---------------------------\u001b[0m\u001b[0m 52.36 KiB/497.29 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)-------------------\u001b[0m\u001b[0m 58.78 KiB/11.79 MiB         \u001b[3A\n",
      "\u001b[2mtzdata              \u001b[0m \u001b[32m----\u001b[30m\u001b[2m--------------------------\u001b[0m\u001b[0m 52.36 KiB/339.69 KiB\n",
      "\u001b[2mpytz                \u001b[0m \u001b[32m---\u001b[30m\u001b[2m---------------------------\u001b[0m\u001b[0m 52.36 KiB/497.29 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)-------------------\u001b[0m\u001b[0m 74.78 KiB/11.79 MiB         \u001b[3A\n",
      "\u001b[2mtzdata              \u001b[0m \u001b[32m--------\u001b[30m\u001b[2m----------------------\u001b[0m\u001b[0m 92.74 KiB/339.69 KiB\n",
      "\u001b[2mpytz                \u001b[0m \u001b[32m------\u001b[30m\u001b[2m------------------------\u001b[0m\u001b[0m 110.09 KiB/497.29 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)-------------------\u001b[0m\u001b[0m 106.96 KiB/11.79 MiB        \u001b[3A\n",
      "\u001b[2mtzdata              \u001b[0m \u001b[32m---------------\u001b[30m\u001b[2m---------------\u001b[0m\u001b[0m 172.74 KiB/339.69 KiB\n",
      "\u001b[2mpytz                \u001b[0m \u001b[32m-----------\u001b[30m\u001b[2m-------------------\u001b[0m\u001b[0m 190.09 KiB/497.29 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)-------------------\u001b[0m\u001b[0m 202.96 KiB/11.79 MiB        \u001b[3A\n",
      "\u001b[2mtzdata              \u001b[0m \u001b[32m--------------------\u001b[30m\u001b[2m----------\u001b[0m\u001b[0m 236.74 KiB/339.69 KiB\n",
      "\u001b[2mpytz                \u001b[0m \u001b[32m-----------------\u001b[30m\u001b[2m-------------\u001b[0m\u001b[0m 286.09 KiB/497.29 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)-------------------\u001b[0m\u001b[0m 398.96 KiB/11.79 MiB        \u001b[3A\n",
      "\u001b[2mtzdata              \u001b[0m \u001b[32m------------------------------\u001b[30m\u001b[2m\u001b[0m\u001b[0m 339.69 KiB/339.69 KiB\n",
      "\u001b[2mpytz                \u001b[0m \u001b[32m------------------------\u001b[30m\u001b[2m------\u001b[0m\u001b[0m 398.09 KiB/497.29 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)-------------------\u001b[0m\u001b[0m 1.28 MiB/11.79 MiB          \u001b[3A\n",
      "\u001b[2mpytz                \u001b[0m \u001b[32m------------------------\u001b[30m\u001b[2m------\u001b[0m\u001b[0m 414.09 KiB/497.29 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)-------------------\u001b[0m\u001b[0m 2.00 MiB/11.79 MiB          \u001b[2A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/3)-------------------\u001b[0m\u001b[0m 2.00 MiB/11.79 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/3)-------------------\u001b[0m\u001b[0m 2.67 MiB/11.79 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/3)-------------------\u001b[0m\u001b[0m 3.96 MiB/11.79 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/3)m------------------\u001b[0m\u001b[0m 4.96 MiB/11.79 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/3)\u001b[2m---------------\u001b[0m\u001b[0m 6.09 MiB/11.79 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/3)30m\u001b[2m------------\u001b[0m\u001b[0m 7.43 MiB/11.79 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/3)-\u001b[30m\u001b[2m---------\u001b[0m\u001b[0m 8.52 MiB/11.79 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/3)-\u001b[30m\u001b[2m---------\u001b[0m\u001b[0m 8.53 MiB/11.79 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/3)--\u001b[30m\u001b[2m--------\u001b[0m\u001b[0m 9.04 MiB/11.79 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/3)----\u001b[30m\u001b[2m------\u001b[0m\u001b[0m 9.70 MiB/11.79 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/3)------\u001b[30m\u001b[2m----\u001b[0m\u001b[0m 10.33 MiB/11.79 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (2/3)--------\u001b[30m\u001b[2m--\u001b[0m\u001b[0m 11.05 MiB/11.79 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 955ms\u001b[0m\u001b[0m                                                      \u001b[1A\n",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/3] \u001b[2mInstalling wheels...                                 \u001b[0m\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 297ms\u001b[0m\u001b[0m                               \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.3.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpytz\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2025.2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d4ab602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "inputs = [\n",
    "    \"Why does Anne begin attending church even though she does not value the sermons?\",\n",
    "    \"What inner conflict does Anne experience after receiving old Willy’s bequest?\",\n",
    "    \"How does Anne learn the true challenges of working in the garden?\",\n",
    "]\n",
    "\n",
    "outputs = [\n",
    "    \"Anne attends church not for the sermon, but for a sense of 'keeping step' with the community, as Miss Abby explains that people go to stay in rhythm with others rather than for the preaching.\",\n",
    "\n",
    "    \"Anne feels deep self-reproach after Willy's bequest because the old woman had loved and depended on her long before Anne ever intended to care for her. She realizes she only stayed because of her own need, not Willy’s, and confronts her past failures toward those who depended on her.\",\n",
    "\n",
    "    \"Anne discovers the real difficulty of gardening when her first attempts leave her tired, frustrated, and unsuccessful. She learns that working with nature requires patience and timing, and that the earth only becomes workable when it is ready—not when she wants it to be.\",\n",
    "]\n",
    "\n",
    "qa_pairs = [{\"question\": q, \"answer\": a} for q, a in zip(inputs, outputs)]\n",
    "df = pd.DataFrame(qa_pairs)\n",
    "\n",
    "# Write to csv\n",
    "csv_path = \"/workspaces/End2End_RAG/data/goldens.csv\"\n",
    "df.to_csv(csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5795e467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_ids': ['1419eae8-06e5-4e53-97ac-6652dda62e2e',\n",
       "  'dee59ebc-2745-4460-8b09-8ec78d016bff',\n",
       "  '16a9b6b4-6427-4eba-a067-41dc15b72efd'],\n",
       " 'count': 3}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"AgenticAIReportGoldens\"\n",
    "\n",
    "# Store\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Input and expected output pairs for AgenticAIReport\",\n",
    ")\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": q} for q in inputs],\n",
    "    outputs=[{\"answer\": a} for a in outputs],\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c340e11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/workspaces/End2End_RAG\")\n",
    "\n",
    "from pathlib import Path\n",
    "from multi_doc_chat.src.document_ingestion.document_ingestion import ChatIngestor\n",
    "from multi_doc_chat.src.document_chat.retrieval import ConversationalRAG\n",
    "import os\n",
    "\n",
    "# Simple file adapter for local file paths\n",
    "class LocalFileAdapter:\n",
    "    \"\"\"Adapter for local file paths to work with ChatIngestor.\"\"\"\n",
    "    def __init__(self, file_path: str):\n",
    "        self.path = Path(file_path)\n",
    "        self.name = self.path.name\n",
    "    \n",
    "    def getbuffer(self) -> bytes:\n",
    "        return self.path.read_bytes()\n",
    "\n",
    "\n",
    "def answer_ai_report_question(\n",
    "    inputs: dict,\n",
    "    data_path: str = \"/workspaces/End2End_RAG/data/Way of All Earth.txt\",\n",
    "    chunk_size: int = 1000,\n",
    "    chunk_overlap: int = 200,\n",
    "    k: int = 5\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Answer questions about the AI Engineering Report using RAG.\n",
    "    \n",
    "    Args:\n",
    "        inputs: Dictionary containing the question, e.g., {\"question\": \"What is RAG?\"}\n",
    "        data_path: Path to the AI Engineering Report text file\n",
    "        chunk_size: Size of text chunks for splitting\n",
    "        chunk_overlap: Overlap between chunks\n",
    "        k: Number of documents to retrieve\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with the answer, e.g., {\"answer\": \"RAG stands for...\"}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract question from inputs\n",
    "        question = inputs.get(\"question\", \"\")\n",
    "        if not question:\n",
    "            return {\"answer\": \"No question provided\"}\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not Path(data_path).exists():\n",
    "            return {\"answer\": f\"Data file not found: {data_path}\"}\n",
    "        \n",
    "        # Create file adapter\n",
    "        file_adapter = LocalFileAdapter(data_path)\n",
    "        \n",
    "        # Build index using ChatIngestor\n",
    "        ingestor = ChatIngestor(\n",
    "            temp_base=\"data\",\n",
    "            faiss_base=\"faiss_index\",\n",
    "            use_session_dirs=True\n",
    "        )\n",
    "        \n",
    "        # Build retriever\n",
    "        ingestor.built_retriver(\n",
    "            uploaded_files=[file_adapter],\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            k=k\n",
    "        )\n",
    "        \n",
    "        # Get session ID and index path\n",
    "        session_id = ingestor.session_id\n",
    "        index_path = f\"faiss_index/{session_id}\"\n",
    "        \n",
    "        # Create RAG instance and load retriever\n",
    "        rag = ConversationalRAG(session_id=session_id)\n",
    "        rag.load_retriever_from_faiss(\n",
    "            index_path=index_path,\n",
    "            k=k,\n",
    "            index_name=os.getenv(\"FAISS_INDEX_NAME\", \"index\")\n",
    "        )\n",
    "        \n",
    "        # Get answer\n",
    "        answer = rag.invoke(question, chat_history=[])\n",
    "        \n",
    "        return {\"answer\": answer}\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"answer\": f\"Error: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "336a1a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"timestamp\": \"2025-12-01T15:12:38.291843Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T15:12:38.293850Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T15:12:38.295290Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T15:12:38.302923Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251201_151238_26d3462d\", \"temp_dir\": \"data/session_20251201_151238_26d3462d\", \"faiss_dir\": \"faiss_index/session_20251201_151238_26d3462d\", \"sessionized\": true, \"timestamp\": \"2025-12-01T15:12:38.310186Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"Way of All Earth.txt\", \"saved_as\": \"data/session_20251201_151238_26d3462d/ad6ff42f.txt\", \"timestamp\": \"2025-12-01T15:12:38.325222Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2025-12-01T15:12:38.330104Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 531, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-12-01T15:12:38.350469Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"huggingface\", \"timestamp\": \"2025-12-01T15:12:38.351361Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Use pytorch device_name: cpu\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "Loading faiss with AVX2 support.\n",
      "Successfully loaded faiss with AVX2 support.\n",
      "{\"added\": 1, \"index\": \"faiss_index/session_20251201_151238_26d3462d\", \"timestamp\": \"2025-12-01T15:18:03.711026Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-12-01T15:18:03.711925Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-12-01T15:18:03.714723Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T15:18:03.715257Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T15:18:03.716213Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T15:18:03.718350Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.5-flash\", \"timestamp\": \"2025-12-01T15:18:03.718825Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251201_151238_26d3462d\", \"timestamp\": \"2025-12-01T15:18:03.874519Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251201_151238_26d3462d\", \"timestamp\": \"2025-12-01T15:18:03.875223Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-12-01T15:18:03.877629Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T15:18:03.878168Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T15:18:03.879144Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T15:18:03.881274Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"huggingface\", \"timestamp\": \"2025-12-01T15:18:03.882421Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Use pytorch device_name: cpu\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "{\"session_id\": \"session_20251201_151238_26d3462d\", \"timestamp\": \"2025-12-01T15:18:06.794307Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251201_151238_26d3462d\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251201_151238_26d3462d\", \"timestamp\": \"2025-12-01T15:18:06.794982Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251201_151238_26d3462d\", \"user_input\": \"Why does Anne begin attending church even though she does not value the sermons?\", \"answer_preview\": \"I don't know. The context states that Miss Abby believes people don't go to church to hear the sermon, and that she herself now goes regularly. Howeve\", \"timestamp\": \"2025-12-01T15:18:11.741370Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Why does Anne begin attending church even though she does not value the sermons?\n",
      "\n",
      "Answer: I don't know. The context states that Miss Abby believes people don't go to church to hear the sermon, and that she herself now goes regularly. However, it does not explicitly state Anne's reasons for attending.\n"
     ]
    }
   ],
   "source": [
    "test_input = {\"question\": \"Why does Anne begin attending church even though she does not value the sermons?\"}\n",
    "result = answer_ai_report_question(test_input)\n",
    "print(\"Question:\", test_input[\"question\"])\n",
    "print(\"\\nAnswer:\", result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db99da31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d598e213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"timestamp\": \"2025-12-01T15:23:33.444157Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T15:23:33.445117Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T15:23:33.448408Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T15:23:33.457002Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251201_152333_5de968de\", \"temp_dir\": \"data/session_20251201_152333_5de968de\", \"faiss_dir\": \"faiss_index/session_20251201_152333_5de968de\", \"sessionized\": true, \"timestamp\": \"2025-12-01T15:23:33.459917Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"Way of All Earth.txt\", \"saved_as\": \"data/session_20251201_152333_5de968de/1f4d0614.txt\", \"timestamp\": \"2025-12-01T15:23:33.467053Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2025-12-01T15:23:33.472257Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 531, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-12-01T15:23:33.487317Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"huggingface\", \"timestamp\": \"2025-12-01T15:23:33.488913Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Use pytorch device_name: cpu\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing all questions from the dataset:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"added\": 1, \"index\": \"faiss_index/session_20251201_152333_5de968de\", \"timestamp\": \"2025-12-01T15:28:18.407568Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-12-01T15:28:18.408381Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-12-01T15:28:18.410787Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T15:28:18.411284Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T15:28:18.412189Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T15:28:18.413748Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.5-flash\", \"timestamp\": \"2025-12-01T15:28:18.414604Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251201_152333_5de968de\", \"timestamp\": \"2025-12-01T15:28:18.416564Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251201_152333_5de968de\", \"timestamp\": \"2025-12-01T15:28:18.417120Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-12-01T15:28:18.418981Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T15:28:18.419745Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T15:28:18.420316Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T15:28:18.423075Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"huggingface\", \"timestamp\": \"2025-12-01T15:28:18.423518Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Use pytorch device_name: cpu\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "{\"session_id\": \"session_20251201_152333_5de968de\", \"timestamp\": \"2025-12-01T15:28:21.829716Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251201_152333_5de968de\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251201_152333_5de968de\", \"timestamp\": \"2025-12-01T15:28:21.830429Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251201_152333_5de968de\", \"user_input\": \"Why does Anne begin attending church even though she does not value the sermons?\", \"answer_preview\": \"I don't know. The context states that Miss Abby believes people don't go to church to hear the sermon, and that she herself now goes regularly. Howeve\", \"timestamp\": \"2025-12-01T15:28:26.630318Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "{\"timestamp\": \"2025-12-01T15:28:26.632685Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T15:28:26.633210Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T15:28:26.634329Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T15:28:26.635879Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251201_152826_2c08ec2e\", \"temp_dir\": \"data/session_20251201_152826_2c08ec2e\", \"faiss_dir\": \"faiss_index/session_20251201_152826_2c08ec2e\", \"sessionized\": true, \"timestamp\": \"2025-12-01T15:28:26.636725Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"Way of All Earth.txt\", \"saved_as\": \"data/session_20251201_152826_2c08ec2e/cdf9224a.txt\", \"timestamp\": \"2025-12-01T15:28:26.638280Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2025-12-01T15:28:26.639899Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 531, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-12-01T15:28:26.661623Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"huggingface\", \"timestamp\": \"2025-12-01T15:28:26.662599Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Use pytorch device_name: cpu\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: Why does Anne begin attending church even though she does not value the sermons?\n",
      "A1: I don't know. The context states that Miss Abby believes people don't go to church to hear the sermon, and that she herself now goes regularly. However, it does not explicitly state Anne's reasons for attending.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"added\": 1, \"index\": \"faiss_index/session_20251201_152826_2c08ec2e\", \"timestamp\": \"2025-12-01T15:33:10.523475Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-12-01T15:33:10.524474Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-12-01T15:33:10.527794Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T15:33:10.528594Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T15:33:10.529592Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T15:33:10.531934Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.5-flash\", \"timestamp\": \"2025-12-01T15:33:10.532856Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251201_152826_2c08ec2e\", \"timestamp\": \"2025-12-01T15:33:10.535210Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251201_152826_2c08ec2e\", \"timestamp\": \"2025-12-01T15:33:10.536100Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-12-01T15:33:10.538153Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T15:33:10.538963Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T15:33:10.542869Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T15:33:10.546448Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"huggingface\", \"timestamp\": \"2025-12-01T15:33:10.547019Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Use pytorch device_name: cpu\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "{\"session_id\": \"session_20251201_152826_2c08ec2e\", \"timestamp\": \"2025-12-01T15:33:13.514264Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251201_152826_2c08ec2e\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251201_152826_2c08ec2e\", \"timestamp\": \"2025-12-01T15:33:13.515300Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251201_152826_2c08ec2e\", \"user_input\": \"What inner conflict does Anne experience after receiving old Willy\\u2019s bequest?\", \"answer_preview\": \"After receiving old Willy's bequest, Anne experiences a new feeling of dull self-reproach and a consciousness of failure. She realizes that Willy had \", \"timestamp\": \"2025-12-01T15:33:17.649022Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "{\"timestamp\": \"2025-12-01T15:33:17.651630Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T15:33:17.652740Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T15:33:17.653251Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T15:33:17.655047Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251201_153317_bde36f2d\", \"temp_dir\": \"data/session_20251201_153317_bde36f2d\", \"faiss_dir\": \"faiss_index/session_20251201_153317_bde36f2d\", \"sessionized\": true, \"timestamp\": \"2025-12-01T15:33:17.655937Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"Way of All Earth.txt\", \"saved_as\": \"data/session_20251201_153317_bde36f2d/ddd32177.txt\", \"timestamp\": \"2025-12-01T15:33:17.657626Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2025-12-01T15:33:17.659216Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 531, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-12-01T15:33:17.680635Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"huggingface\", \"timestamp\": \"2025-12-01T15:33:17.681453Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Use pytorch device_name: cpu\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2: What inner conflict does Anne experience after receiving old Willy’s bequest?\n",
      "A2: After receiving old Willy's bequest, Anne experiences a new feeling of dull self-reproach and a consciousness of failure. She realizes that Willy had loved her and perhaps dreamed of her care in her old age, a role Anne did not fulfill, despite the \"kindly falsehood\" she tells neighbors about coming to take care of her. This feeling is unmixed with anger, unlike her past conflicts.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"added\": 1, \"index\": \"faiss_index/session_20251201_153317_bde36f2d\", \"timestamp\": \"2025-12-01T15:37:59.309851Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-12-01T15:37:59.310944Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-12-01T15:37:59.313596Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T15:37:59.314182Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T15:37:59.314837Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T15:37:59.316820Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.5-flash\", \"timestamp\": \"2025-12-01T15:37:59.317645Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251201_153317_bde36f2d\", \"timestamp\": \"2025-12-01T15:37:59.319470Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251201_153317_bde36f2d\", \"timestamp\": \"2025-12-01T15:37:59.320086Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-12-01T15:37:59.321879Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T15:37:59.322434Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T15:37:59.323303Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T15:37:59.325347Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"huggingface\", \"timestamp\": \"2025-12-01T15:37:59.325740Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Use pytorch device_name: cpu\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "{\"session_id\": \"session_20251201_153317_bde36f2d\", \"timestamp\": \"2025-12-01T15:38:02.250943Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251201_153317_bde36f2d\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251201_153317_bde36f2d\", \"timestamp\": \"2025-12-01T15:38:02.252112Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251201_153317_bde36f2d\", \"user_input\": \"How does Anne learn the true challenges of working in the garden?\", \"answer_preview\": \"Anne learns the true challenges of working in the garden when she attempts tasks like scraping out rows and making the dirt fine, which leaves her sho\", \"timestamp\": \"2025-12-01T15:38:06.639228Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3: How does Anne learn the true challenges of working in the garden?\n",
      "A3: Anne learns the true challenges of working in the garden when she attempts tasks like scraping out rows and making the dirt fine, which leaves her shoulders aching. She realizes that what she thought was simple is intricate, leading to feelings of humility and helplessness. She also discovers that seemingly trivial details, like how corn is planted, make a significant difference, and that tasks like weeding beets are laborious and back-breaking.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example: Test with all golden questions\n",
    "print(\"Testing all questions from the dataset:\\n\")\n",
    "for i, q in enumerate(inputs, 1):\n",
    "    test_input = {\"question\": q}\n",
    "    result = answer_ai_report_question(test_input)\n",
    "    print(f\"Q{i}: {q}\")\n",
    "    print(f\"A{i}: {result['answer']}\\n\")\n",
    "    print(\"-\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83187f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.1 environment at: /workspaces/End2End_RAG/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m19 packages\u001b[0m \u001b[2min 2.02s\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m     0 B/110.71 KiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 14.85 KiB/110.71 KiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 30.85 KiB/110.71 KiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------------------\u001b[0m\u001b[0m 42.29 KiB/110.71 KiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)[2m----------------\u001b[0m\u001b[0m 53.27 KiB/110.71 KiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\u001b[2m---------------\u001b[0m\u001b[0m 58.75 KiB/110.71 KiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)30m\u001b[2m------------\u001b[0m\u001b[0m 69.73 KiB/110.71 KiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-\u001b[30m\u001b[2m---------\u001b[0m\u001b[0m 78.85 KiB/110.71 KiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-----\u001b[30m\u001b[2m-----\u001b[0m\u001b[0m 94.85 KiB/110.71 KiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----------\u001b[30m\u001b[2m\u001b[0m\u001b[0m 110.71 KiB/110.71 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 159ms\u001b[0m\u001b[0m                                                       \u001b[1A\n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 42ms\u001b[0m\u001b[0m\n",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/1] \u001b[2mInstalling wheels...                                 \u001b[0m\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 12ms\u001b[0m\u001b[0m                                 \u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.11.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.12.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install -U langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cced19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.1 environment at: /workspaces/End2End_RAG/.venv\u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m46 packages\u001b[0m \u001b[2min 2.09s\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)---------------------\u001b[0m\u001b[0m     0 B/204.70 KiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)---------------------\u001b[0m\u001b[0m 14.87 KiB/204.70 KiB      \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)---------------------\u001b[0m\u001b[0m 30.87 KiB/204.70 KiB      \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)---------------------\u001b[0m\u001b[0m 46.87 KiB/204.70 KiB      \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)---------------------\u001b[0m\u001b[0m 62.87 KiB/204.70 KiB      \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)2m-------------------\u001b[0m\u001b[0m 78.87 KiB/204.70 KiB      \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\u001b[2m-----------------\u001b[0m\u001b[0m 94.87 KiB/204.70 KiB      \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)30m\u001b[2m--------------\u001b[0m\u001b[0m 110.87 KiB/204.70 KiB     \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\u001b[30m\u001b[2m------------\u001b[0m\u001b[0m 126.87 KiB/204.70 KiB     \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--\u001b[30m\u001b[2m----------\u001b[0m\u001b[0m 142.87 KiB/204.70 KiB     \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-----\u001b[30m\u001b[2m-------\u001b[0m\u001b[0m 158.87 KiB/204.70 KiB     \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------\u001b[30m\u001b[2m-----\u001b[0m\u001b[0m 174.87 KiB/204.70 KiB     \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)---------\u001b[30m\u001b[2m---\u001b[0m\u001b[0m 190.87 KiB/204.70 KiB     \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)------------\u001b[30m\u001b[2m\u001b[0m\u001b[0m 204.70 KiB/204.70 KiB     \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 182ms\u001b[0m\u001b[0m                                                       \u001b[1A\n",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/1] \u001b[2mInstalling wheels...                                 \u001b[0m\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 24ms\u001b[0m\u001b[0mal==0.4.0                        \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-experimental\u001b[0m\u001b[2m==0.4.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install langchain-experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "caa1f906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'test-agenticAIReport-qa-rag-cb839cb2' at:\n",
      "https://smith.langchain.com/o/a055ffe7-e26c-47b9-aceb-78787385e028/datasets/cb723103-018f-44cb-8504-fc1a432cd953/compare?selectedSessions=37d7415e-5ef3-40a6-be43-6e2322ebe42f\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]{\"timestamp\": \"2025-12-01T16:41:48.632037Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T16:41:48.632778Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T16:41:48.633722Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T16:41:48.635312Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251201_164148_8c4c4890\", \"temp_dir\": \"data/session_20251201_164148_8c4c4890\", \"faiss_dir\": \"faiss_index/session_20251201_164148_8c4c4890\", \"sessionized\": true, \"timestamp\": \"2025-12-01T16:41:48.636491Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"Way of All Earth.txt\", \"saved_as\": \"data/session_20251201_164148_8c4c4890/516998b3.txt\", \"timestamp\": \"2025-12-01T16:41:48.638108Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2025-12-01T16:41:48.639770Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 531, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-12-01T16:41:48.647797Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"huggingface\", \"timestamp\": \"2025-12-01T16:41:48.648635Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Use pytorch device_name: cpu\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "{\"added\": 1, \"index\": \"faiss_index/session_20251201_164148_8c4c4890\", \"timestamp\": \"2025-12-01T16:46:43.335228Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-12-01T16:46:43.336294Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-12-01T16:46:43.338900Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T16:46:43.339561Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T16:46:43.340305Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T16:46:43.342029Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.5-flash\", \"timestamp\": \"2025-12-01T16:46:43.342762Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251201_164148_8c4c4890\", \"timestamp\": \"2025-12-01T16:46:43.344663Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251201_164148_8c4c4890\", \"timestamp\": \"2025-12-01T16:46:43.345341Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-12-01T16:46:43.347127Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T16:46:43.348235Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T16:46:43.349400Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T16:46:43.350891Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"huggingface\", \"timestamp\": \"2025-12-01T16:46:43.351888Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Use pytorch device_name: cpu\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "{\"session_id\": \"session_20251201_164148_8c4c4890\", \"timestamp\": \"2025-12-01T16:46:47.182326Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251201_164148_8c4c4890\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251201_164148_8c4c4890\", \"timestamp\": \"2025-12-01T16:46:47.183014Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251201_164148_8c4c4890\", \"user_input\": \"Why does Anne begin attending church even though she does not value the sermons?\", \"answer_preview\": \"I don't know. The context indicates that Anne is at church and discusses sermons with Miss Abby, who notes that people don't go to church just for the\", \"timestamp\": \"2025-12-01T16:46:53.644774Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "1it [05:05, 305.02s/it]{\"timestamp\": \"2025-12-01T16:46:53.651007Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T16:46:53.651531Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T16:46:53.652447Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T16:46:53.655438Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251201_164653_d96eb5fd\", \"temp_dir\": \"data/session_20251201_164653_d96eb5fd\", \"faiss_dir\": \"faiss_index/session_20251201_164653_d96eb5fd\", \"sessionized\": true, \"timestamp\": \"2025-12-01T16:46:53.657300Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"Way of All Earth.txt\", \"saved_as\": \"data/session_20251201_164653_d96eb5fd/f1c5ea8c.txt\", \"timestamp\": \"2025-12-01T16:46:53.658965Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2025-12-01T16:46:53.662686Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 531, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-12-01T16:46:53.681295Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"huggingface\", \"timestamp\": \"2025-12-01T16:46:53.683730Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Use pytorch device_name: cpu\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "{\"added\": 1, \"index\": \"faiss_index/session_20251201_164653_d96eb5fd\", \"timestamp\": \"2025-12-01T16:51:37.717718Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-12-01T16:51:37.718753Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-12-01T16:51:37.721130Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T16:51:37.721585Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T16:51:37.722210Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T16:51:37.724151Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.5-flash\", \"timestamp\": \"2025-12-01T16:51:37.724617Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251201_164653_d96eb5fd\", \"timestamp\": \"2025-12-01T16:51:37.726679Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251201_164653_d96eb5fd\", \"timestamp\": \"2025-12-01T16:51:37.727443Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-12-01T16:51:37.729088Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T16:51:37.729756Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T16:51:37.730466Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T16:51:37.734501Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"huggingface\", \"timestamp\": \"2025-12-01T16:51:37.735594Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Use pytorch device_name: cpu\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "{\"session_id\": \"session_20251201_164653_d96eb5fd\", \"timestamp\": \"2025-12-01T16:51:40.697268Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251201_164653_d96eb5fd\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251201_164653_d96eb5fd\", \"timestamp\": \"2025-12-01T16:51:40.698081Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251201_164653_d96eb5fd\", \"user_input\": \"How does Anne learn the true challenges of working in the garden?\", \"answer_preview\": \"Anne learns the true challenges of gardening when she attempts the work herself, realizing it's not as simple as she initially thought. Her shoulders \", \"timestamp\": \"2025-12-01T16:51:44.934261Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "2it [09:56, 296.94s/it]{\"timestamp\": \"2025-12-01T16:51:44.941384Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T16:51:44.942440Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T16:51:44.943686Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T16:51:44.946802Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251201_165144_2bfd7bcf\", \"temp_dir\": \"data/session_20251201_165144_2bfd7bcf\", \"faiss_dir\": \"faiss_index/session_20251201_165144_2bfd7bcf\", \"sessionized\": true, \"timestamp\": \"2025-12-01T16:51:44.948530Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"Way of All Earth.txt\", \"saved_as\": \"data/session_20251201_165144_2bfd7bcf/2720ae3e.txt\", \"timestamp\": \"2025-12-01T16:51:44.951124Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2025-12-01T16:51:44.953882Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 531, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-12-01T16:51:44.966612Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"huggingface\", \"timestamp\": \"2025-12-01T16:51:44.967764Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Use pytorch device_name: cpu\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "2it [13:13, 396.84s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m dataset_name = \u001b[33m\"\u001b[39m\u001b[33mAgenticAIReportGoldens\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 2. Run evaluation using your RAG function\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m experiment_results = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer_ai_report_question\u001b[49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Your function to test\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# List of evaluator names\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest-agenticAIReport-qa-rag\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvariant\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRAG with FAISS and AI Engineering Report\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mchunk_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mchunk_overlap\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mk\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(experiment_results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py:421\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment, upload_results, error_handling, **kwargs)\u001b[39m\n\u001b[32m    419\u001b[39m     _warn_once(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mupload_results\u001b[39m\u001b[33m'\u001b[39m\u001b[33m parameter is in beta.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    420\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning evaluation over target system \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOptional\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSequence\u001b[49m\u001b[43m[\u001b[49m\u001b[43mEVALUATOR_T\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m    \u001b[49m\u001b[43msummary_evaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43msummary_evaluators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py:1098\u001b[39m, in \u001b[36m_evaluate\u001b[39m\u001b[34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment, upload_results, error_handling)\u001b[39m\n\u001b[32m   1096\u001b[39m     manager = manager.with_summary_evaluators(summary_evaluators)\n\u001b[32m   1097\u001b[39m \u001b[38;5;66;03m# Start consuming the results.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1098\u001b[39m results = \u001b[43mExperimentResults\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1099\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py:581\u001b[39m, in \u001b[36mExperimentResults.__init__\u001b[39m\u001b[34m(self, experiment_manager, blocking)\u001b[39m\n\u001b[32m    579\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    580\u001b[39m     \u001b[38;5;28mself\u001b[39m._thread = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py:606\u001b[39m, in \u001b[36mExperimentResults._process_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    604\u001b[39m tqdm = _load_tqdm()\n\u001b[32m    605\u001b[39m results = \u001b[38;5;28mself\u001b[39m._manager.get_results()\n\u001b[32m--> \u001b[39m\u001b[32m606\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    608\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_results\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py:1518\u001b[39m, in \u001b[36m_ExperimentManager.get_results\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1516\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_results\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterable[ExperimentResultRow]:\n\u001b[32m   1517\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the traces, evaluation results, and associated examples.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1518\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluation_results\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   1519\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mruns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluation_results\u001b[49m\n\u001b[32m   1520\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1521\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mExperimentResultRow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1523\u001b[39m \u001b[43m            \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1524\u001b[39m \u001b[43m            \u001b[49m\u001b[43mevaluation_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluation_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1525\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py:1473\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1465\u001b[39m _experiment_results = context.run(\n\u001b[32m   1466\u001b[39m     \u001b[38;5;28mself\u001b[39m._predict,\n\u001b[32m   1467\u001b[39m     target,\n\u001b[32m   1468\u001b[39m     max_concurrency=max_concurrency,\n\u001b[32m   1469\u001b[39m     include_attachments=_target_include_attachments(target),\n\u001b[32m   1470\u001b[39m )\n\u001b[32m   1471\u001b[39m r1, r2 = itertools.tee(_experiment_results, \u001b[32m2\u001b[39m)\n\u001b[32m   1472\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._copy(\n\u001b[32m-> \u001b[39m\u001b[32m1473\u001b[39m     (pred[\u001b[33m\"\u001b[39m\u001b[33mexample\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m r1), runs=\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1474\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py:1554\u001b[39m, in \u001b[36m_ExperimentManager._predict\u001b[39m\u001b[34m(self, target, max_concurrency, include_attachments)\u001b[39m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_concurrency == \u001b[32m0\u001b[39m:\n\u001b[32m   1553\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.examples:\n\u001b[32m-> \u001b[39m\u001b[32m1554\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1555\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1556\u001b[39m \u001b[43m            \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1557\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1558\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1559\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1560\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_upload_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1561\u001b[39m \u001b[43m            \u001b[49m\u001b[43minclude_attachments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1562\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1563\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1565\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1566\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ls_utils.ContextThreadPoolExecutor(max_concurrency) \u001b[38;5;28;01mas\u001b[39;00m executor:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/langsmith/evaluation/_runner.py:1920\u001b[39m, in \u001b[36m_forward\u001b[39m\u001b[34m(fn, example, experiment_name, metadata, client, upload_results, include_attachments, error_handling)\u001b[39m\n\u001b[32m   1918\u001b[39m arg_names = _get_target_args(fn)\n\u001b[32m   1919\u001b[39m args = [\u001b[38;5;28mgetattr\u001b[39m(example, argn) \u001b[38;5;28;01mfor\u001b[39;00m argn \u001b[38;5;129;01min\u001b[39;00m arg_names]\n\u001b[32m-> \u001b[39m\u001b[32m1920\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlangsmith_extra\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlangsmith_extra\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1921\u001b[39m \u001b[38;5;66;03m# Reset attachment readers if attachments were used.\u001b[39;00m\n\u001b[32m   1922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m include_attachments \u001b[38;5;129;01mand\u001b[39;00m example.attachments \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 61\u001b[39m, in \u001b[36manswer_ai_report_question\u001b[39m\u001b[34m(inputs, data_path, chunk_size, chunk_overlap, k)\u001b[39m\n\u001b[32m     54\u001b[39m ingestor = ChatIngestor(\n\u001b[32m     55\u001b[39m     temp_base=\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     56\u001b[39m     faiss_base=\u001b[33m\"\u001b[39m\u001b[33mfaiss_index\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     57\u001b[39m     use_session_dirs=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     58\u001b[39m )\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Build retriever\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[43mingestor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuilt_retriver\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43muploaded_files\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfile_adapter\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunk_overlap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_overlap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# Get session ID and index path\u001b[39;00m\n\u001b[32m     69\u001b[39m session_id = ingestor.session_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/multi_doc_chat/src/document_ingestion/document_ingestion.py:92\u001b[39m, in \u001b[36mChatIngestor.built_retriver\u001b[39m\u001b[34m(self, uploaded_files, chunk_size, chunk_overlap, k, search_type, fetch_k, lambda_mult)\u001b[39m\n\u001b[32m     89\u001b[39m metas = [c.metadata \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     vs = \u001b[43mfm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_or_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m     94\u001b[39m     vs = fm.load_or_create(texts=texts, metadatas=metas)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/multi_doc_chat/src/document_ingestion/document_ingestion.py:187\u001b[39m, in \u001b[36mFaissManager.load_or_create\u001b[39m\u001b[34m(self, texts, metadatas)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m texts:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DocumentPortalException(\u001b[33m\"\u001b[39m\u001b[33mNo existing FAISS index and no data to create one\u001b[39m\u001b[33m\"\u001b[39m, sys)\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m \u001b[38;5;28mself\u001b[39m.vs = \u001b[43mFAISS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43memb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28mself\u001b[39m.vs.save_local(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.index_dir))\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.vs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/langchain_community/vectorstores/faiss.py:1043\u001b[39m, in \u001b[36mFAISS.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m   1016\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_texts\u001b[39m(\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1023\u001b[39m     **kwargs: Any,\n\u001b[32m   1024\u001b[39m ) -> FAISS:\n\u001b[32m   1025\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[32m   1026\u001b[39m \n\u001b[32m   1027\u001b[39m \u001b[33;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1041\u001b[39m \u001b[33;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[32m   1042\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m     embeddings = \u001b[43membedding\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1044\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__from(\n\u001b[32m   1045\u001b[39m         texts,\n\u001b[32m   1046\u001b[39m         embeddings,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1050\u001b[39m         **kwargs,\n\u001b[32m   1051\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/langchain_huggingface/embeddings/huggingface.py:155\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[32m    146\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute doc embeddings using a HuggingFace transformer model.\u001b[39;00m\n\u001b[32m    147\u001b[39m \n\u001b[32m    148\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    153\u001b[39m \n\u001b[32m    154\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/langchain_huggingface/embeddings/huggingface.py:130\u001b[39m, in \u001b[36mHuggingFaceEmbeddings._embed\u001b[39m\u001b[34m(self, texts, encode_kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m     sentence_transformers.SentenceTransformer.stop_multi_process_pool(pool)\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(embeddings, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    137\u001b[39m     msg = (\n\u001b[32m    138\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mExpected embeddings to be a Tensor or a numpy array, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mgot a list instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    140\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:1094\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[39m\n\u001b[32m   1091\u001b[39m features.update(extra_features)\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m-> \u001b[39m\u001b[32m1094\u001b[39m     out_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mhpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1096\u001b[39m         out_features = copy.deepcopy(out_features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:1175\u001b[39m, in \u001b[36mSentenceTransformer.forward\u001b[39m\u001b[34m(self, input, **kwargs)\u001b[39m\n\u001b[32m   1169\u001b[39m             module_kwarg_keys = \u001b[38;5;28mself\u001b[39m.module_kwargs.get(module_name, [])\n\u001b[32m   1170\u001b[39m         module_kwargs = {\n\u001b[32m   1171\u001b[39m             key: value\n\u001b[32m   1172\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items()\n\u001b[32m   1173\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33mforward_kwargs\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module.forward_kwargs)\n\u001b[32m   1174\u001b[39m         }\n\u001b[32m-> \u001b[39m\u001b[32m1175\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/sentence_transformers/models/Transformer.py:261\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, features, **kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[33;03mForward pass through the transformer model.\u001b[39;00m\n\u001b[32m    240\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m \u001b[33;03m        - 'all_layer_embeddings': If the model outputs hidden states, contains embeddings from all layers\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    259\u001b[39m trans_features = {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features.items() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_forward_params}\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m token_embeddings = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    263\u001b[39m features[\u001b[33m\"\u001b[39m\u001b[33mtoken_embeddings\u001b[39m\u001b[33m\"\u001b[39m] = token_embeddings\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/transformers/models/mpnet/modeling_mpnet.py:486\u001b[39m, in \u001b[36mMPNetModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[39m\n\u001b[32m    484\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m    485\u001b[39m embedding_output = \u001b[38;5;28mself\u001b[39m.embeddings(input_ids=input_ids, position_ids=position_ids, inputs_embeds=inputs_embeds)\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    495\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/transformers/models/mpnet/modeling_mpnet.py:338\u001b[39m, in \u001b[36mMPNetEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[39m\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    336\u001b[39m     all_hidden_states = all_hidden_states + (hidden_states,)\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/transformers/models/mpnet/modeling_mpnet.py:297\u001b[39m, in \u001b[36mMPNetLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[39m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    289\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    290\u001b[39m     hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    295\u001b[39m     **kwargs,\n\u001b[32m    296\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     self_attention_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    304\u001b[39m     attention_output = self_attention_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    305\u001b[39m     outputs = self_attention_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add self attentions if we output attention weights\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/transformers/models/mpnet/modeling_mpnet.py:238\u001b[39m, in \u001b[36mMPNetAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[39m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    230\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    231\u001b[39m     hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    236\u001b[39m     **kwargs,\n\u001b[32m    237\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m     self_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     attention_output = \u001b[38;5;28mself\u001b[39m.LayerNorm(\u001b[38;5;28mself\u001b[39m.dropout(self_outputs[\u001b[32m0\u001b[39m]) + hidden_states)\n\u001b[32m    246\u001b[39m     outputs = (attention_output,) + self_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/transformers/models/mpnet/modeling_mpnet.py:163\u001b[39m, in \u001b[36mMPNetSelfAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[39m\n\u001b[32m    156\u001b[39m batch_size, seq_length, _ = hidden_states.shape\n\u001b[32m    157\u001b[39m q = (\n\u001b[32m    158\u001b[39m     \u001b[38;5;28mself\u001b[39m.q(hidden_states)\n\u001b[32m    159\u001b[39m     .view(batch_size, -\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.num_attention_heads, \u001b[38;5;28mself\u001b[39m.attention_head_size)\n\u001b[32m    160\u001b[39m     .transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    161\u001b[39m )\n\u001b[32m    162\u001b[39m k = (\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m     .view(batch_size, -\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.num_attention_heads, \u001b[38;5;28mself\u001b[39m.attention_head_size)\n\u001b[32m    165\u001b[39m     .transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    166\u001b[39m )\n\u001b[32m    167\u001b[39m v = (\n\u001b[32m    168\u001b[39m     \u001b[38;5;28mself\u001b[39m.v(hidden_states)\n\u001b[32m    169\u001b[39m     .view(batch_size, -\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.num_attention_heads, \u001b[38;5;28mself\u001b[39m.attention_head_size)\n\u001b[32m    170\u001b[39m     .transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    171\u001b[39m )\n\u001b[32m    173\u001b[39m \u001b[38;5;66;03m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/End2End_RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# 1. Choose an evaluator – \"cot_qa\" works here\n",
    "qa_evaluator = [\"cot_qa\"]\n",
    "\n",
    "dataset_name = \"AgenticAIReportGoldens\"\n",
    "\n",
    "# 2. Run evaluation using your RAG function\n",
    "experiment_results = evaluate(\n",
    "    answer_ai_report_question,     # Your function to test\n",
    "    data=dataset_name,       # List of evaluator names\n",
    "    experiment_prefix=\"test-agenticAIReport-qa-rag\",\n",
    "    metadata={\n",
    "        \"variant\": \"RAG with FAISS and AI Engineering Report\",\n",
    "        \"chunk_size\": 1000,\n",
    "        \"chunk_overlap\": 200,\n",
    "        \"k\": 5,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(experiment_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "804e573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.schemas import Run, Example\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def correctness_evaluator(run: Run, example: Example) -> dict:\n",
    "    \"\"\"\n",
    "    Custom LLM-as-a-Judge evaluator for correctness.\n",
    "    \n",
    "    Correctness means how well the actual model output matches the reference output \n",
    "    in terms of factual accuracy, coverage, and meaning.\n",
    "    \n",
    "    Args:\n",
    "        run: The Run object containing the actual outputs\n",
    "        example: The Example object containing the expected outputs\n",
    "    \n",
    "    Returns:\n",
    "        dict with 'score' (1 for correct, 0 for incorrect) and 'reasoning'\n",
    "    \"\"\"\n",
    "    # Extract actual and expected outputs\n",
    "    actual_output = run.outputs.get(\"answer\", \"\")\n",
    "    expected_output = example.outputs.get(\"answer\", \"\")\n",
    "    input_question = example.inputs.get(\"question\", \"\")\n",
    "    \n",
    "    # Define the evaluation prompt\n",
    "    eval_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are an evaluator whose job is to judge correctness.\n",
    "\n",
    "Correctness means how well the actual model output matches the reference output in terms of factual accuracy, coverage, and meaning.\n",
    "\n",
    "- If the actual output matches the reference output semantically (even if wording differs), it should be marked correct.\n",
    "- If the output misses key facts, introduces contradictions, or is factually incorrect, it should be marked incorrect.\n",
    "\n",
    "Do not penalize for stylistic or formatting differences unless they change meaning.\"\"\"),\n",
    "        (\"human\", \"\"\"<example>\n",
    "<input>\n",
    "{input}\n",
    "</input>\n",
    "\n",
    "<output>\n",
    "Expected Output: {expected_output}\n",
    "\n",
    "Actual Output: {actual_output}\n",
    "</output>\n",
    "</example>\n",
    "\n",
    "Please grade the following agent run given the input, expected output, and actual output.\n",
    "Focus only on correctness (semantic and factual alignment).\n",
    "\n",
    "Respond with:\n",
    "1. A brief reasoning (1-2 sentences)\n",
    "2. A final verdict: either \"CORRECT\" or \"INCORRECT\"\n",
    "\n",
    "Format your response as:\n",
    "Reasoning: [your reasoning]\n",
    "Verdict: [CORRECT or INCORRECT]\"\"\")\n",
    "    ])\n",
    "    \n",
    "    # Initialize LLM (using Gemini as shown in your config)\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-pro\",\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    # Create chain and invoke\n",
    "    chain = eval_prompt | llm\n",
    "    \n",
    "    try:\n",
    "        response = chain.invoke({\n",
    "            \"input\": input_question,\n",
    "            \"expected_output\": expected_output,\n",
    "            \"actual_output\": actual_output\n",
    "        })\n",
    "        \n",
    "        response_text = response.content\n",
    "        \n",
    "        # Parse the response\n",
    "        reasoning = \"\"\n",
    "        verdict = \"\"\n",
    "        \n",
    "        for line in response_text.split('\\n'):\n",
    "            if line.startswith(\"Reasoning:\"):\n",
    "                reasoning = line.replace(\"Reasoning:\", \"\").strip()\n",
    "            elif line.startswith(\"Verdict:\"):\n",
    "                verdict = line.replace(\"Verdict:\", \"\").strip()\n",
    "        \n",
    "        # Convert verdict to score (1 for correct, 0 for incorrect)\n",
    "        score = 1 if \"CORRECT\" in verdict.upper() else 0\n",
    "        \n",
    "        return {\n",
    "            \"key\": \"correctness\",\n",
    "            \"score\": score,\n",
    "            \"reasoning\": reasoning,\n",
    "            \"comment\": f\"Verdict: {verdict}\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"key\": \"correctness\",\n",
    "            \"score\": 0,\n",
    "            \"reasoning\": f\"Error during evaluation: {str(e)}\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7472500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'agenticAIReport-correctness-eval-93ce3a36' at:\n",
      "https://smith.langchain.com/o/a055ffe7-e26c-47b9-aceb-78787385e028/datasets/cb723103-018f-44cb-8504-fc1a432cd953/compare?selectedSessions=71002bd2-cefa-47ff-b160-055a152c4ebc\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]{\"timestamp\": \"2025-12-01T16:56:02.448647Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T16:56:02.450114Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T16:56:02.451467Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T16:56:02.453249Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251201_165602_48181686\", \"temp_dir\": \"data/session_20251201_165602_48181686\", \"faiss_dir\": \"faiss_index/session_20251201_165602_48181686\", \"sessionized\": true, \"timestamp\": \"2025-12-01T16:56:02.454125Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"Way of All Earth.txt\", \"saved_as\": \"data/session_20251201_165602_48181686/e3f81822.txt\", \"timestamp\": \"2025-12-01T16:56:02.455596Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2025-12-01T16:56:02.457255Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 531, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-12-01T16:56:02.465966Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"huggingface\", \"timestamp\": \"2025-12-01T16:56:02.466790Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Use pytorch device_name: cpu\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "{\"added\": 1, \"index\": \"faiss_index/session_20251201_165602_48181686\", \"timestamp\": \"2025-12-01T17:00:52.251853Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-12-01T17:00:52.252645Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-12-01T17:00:52.255201Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T17:00:52.256132Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T17:00:52.256618Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T17:00:52.258526Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.5-flash\", \"timestamp\": \"2025-12-01T17:00:52.259286Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251201_165602_48181686\", \"timestamp\": \"2025-12-01T17:00:52.261174Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251201_165602_48181686\", \"timestamp\": \"2025-12-01T17:00:52.261678Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-12-01T17:00:52.263552Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T17:00:52.264369Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T17:00:52.264826Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T17:00:52.267182Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"huggingface\", \"timestamp\": \"2025-12-01T17:00:52.268140Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Use pytorch device_name: cpu\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "{\"session_id\": \"session_20251201_165602_48181686\", \"timestamp\": \"2025-12-01T17:00:55.306850Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251201_165602_48181686\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251201_165602_48181686\", \"timestamp\": \"2025-12-01T17:00:55.309857Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251201_165602_48181686\", \"user_input\": \"Why does Anne begin attending church even though she does not value the sermons?\", \"answer_preview\": \"I don't know. The context indicates that Anne is at church and discusses sermons with Miss Abby, who notes that people don't go to church just for the\", \"timestamp\": \"2025-12-01T17:01:01.220537Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "1it [05:06, 306.82s/it]{\"timestamp\": \"2025-12-01T17:01:09.271531Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T17:01:09.272009Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T17:01:09.273128Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T17:01:09.274798Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251201_170109_e4fc329b\", \"temp_dir\": \"data/session_20251201_170109_e4fc329b\", \"faiss_dir\": \"faiss_index/session_20251201_170109_e4fc329b\", \"sessionized\": true, \"timestamp\": \"2025-12-01T17:01:09.275639Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"Way of All Earth.txt\", \"saved_as\": \"data/session_20251201_170109_e4fc329b/9ef5ffe3.txt\", \"timestamp\": \"2025-12-01T17:01:09.277115Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2025-12-01T17:01:09.278575Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 531, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-12-01T17:01:09.285676Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"huggingface\", \"timestamp\": \"2025-12-01T17:01:09.286279Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Use pytorch device_name: cpu\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "{\"added\": 1, \"index\": \"faiss_index/session_20251201_170109_e4fc329b\", \"timestamp\": \"2025-12-01T17:05:51.969294Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-12-01T17:05:51.970184Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-12-01T17:05:51.974477Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T17:05:51.978185Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T17:05:51.980654Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T17:05:51.983380Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.5-flash\", \"timestamp\": \"2025-12-01T17:05:51.986767Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251201_170109_e4fc329b\", \"timestamp\": \"2025-12-01T17:05:51.992376Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251201_170109_e4fc329b\", \"timestamp\": \"2025-12-01T17:05:51.995184Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-12-01T17:05:52.002480Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T17:05:52.006176Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T17:05:52.008546Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T17:05:52.010805Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"huggingface\", \"timestamp\": \"2025-12-01T17:05:52.013724Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Use pytorch device_name: cpu\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "{\"session_id\": \"session_20251201_170109_e4fc329b\", \"timestamp\": \"2025-12-01T17:05:55.203809Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251201_170109_e4fc329b\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251201_170109_e4fc329b\", \"timestamp\": \"2025-12-01T17:05:55.204495Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251201_170109_e4fc329b\", \"user_input\": \"How does Anne learn the true challenges of working in the garden?\", \"answer_preview\": \"Anne learns the true challenges of gardening when she attempts the work herself, realizing it's not as simple as she initially thought. Her shoulders \", \"timestamp\": \"2025-12-01T17:05:59.288693Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "2it [10:05, 302.20s/it]{\"timestamp\": \"2025-12-01T17:06:08.237531Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T17:06:08.238309Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T17:06:08.238964Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T17:06:08.240767Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20251201_170608_ea7b8021\", \"temp_dir\": \"data/session_20251201_170608_ea7b8021\", \"faiss_dir\": \"faiss_index/session_20251201_170608_ea7b8021\", \"sessionized\": true, \"timestamp\": \"2025-12-01T17:06:08.241813Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"Way of All Earth.txt\", \"saved_as\": \"data/session_20251201_170608_ea7b8021/75276b0d.txt\", \"timestamp\": \"2025-12-01T17:06:08.243228Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2025-12-01T17:06:08.244690Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 531, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-12-01T17:06:08.251998Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"huggingface\", \"timestamp\": \"2025-12-01T17:06:08.252794Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Use pytorch device_name: cpu\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "{\"added\": 1, \"index\": \"faiss_index/session_20251201_170608_ea7b8021\", \"timestamp\": \"2025-12-01T17:10:51.006203Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-12-01T17:10:51.006970Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-12-01T17:10:51.009374Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T17:10:51.010135Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T17:10:51.010654Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T17:10:51.012559Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.5-flash\", \"timestamp\": \"2025-12-01T17:10:51.013236Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251201_170608_ea7b8021\", \"timestamp\": \"2025-12-01T17:10:51.014995Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251201_170608_ea7b8021\", \"timestamp\": \"2025-12-01T17:10:51.015483Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-12-01T17:10:51.017388Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2025-12-01T17:10:51.017934Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-12-01T17:10:51.018635Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm_model\"], \"timestamp\": \"2025-12-01T17:10:51.020597Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"huggingface\", \"timestamp\": \"2025-12-01T17:10:51.021257Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Use pytorch device_name: cpu\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "{\"session_id\": \"session_20251201_170608_ea7b8021\", \"timestamp\": \"2025-12-01T17:10:53.961145Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251201_170608_ea7b8021\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251201_170608_ea7b8021\", \"timestamp\": \"2025-12-01T17:10:53.961833Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251201_170608_ea7b8021\", \"user_input\": \"What inner conflict does Anne experience after receiving old Willy\\u2019s bequest?\", \"answer_preview\": \"After receiving old Willy's bequest, Anne experiences a new feeling of dull self-reproach and a consciousness of failure. She realizes that Willy had \", \"timestamp\": \"2025-12-01T17:10:58.758811Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "3it [15:06, 302.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation completed! Check the LangSmith UI for detailed results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation with the custom correctness evaluator\n",
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# Define evaluators - using custom correctness evaluator\n",
    "evaluators = [correctness_evaluator]\n",
    "\n",
    "dataset_name = \"AgenticAIReportGoldens\"\n",
    "\n",
    "# Run evaluation\n",
    "experiment_results = evaluate(\n",
    "    answer_ai_report_question,\n",
    "    data=dataset_name,\n",
    "    evaluators=evaluators,\n",
    "    experiment_prefix=\"agenticAIReport-correctness-eval\",\n",
    "    description=\"Evaluating RAG system with custom correctness evaluator (LLM-as-a-Judge)\",\n",
    "    metadata={\n",
    "        \"variant\": \"RAG with FAISS and AI Engineering Report\",\n",
    "        \"evaluator\": \"custom_correctness_llm_judge\",\n",
    "        \"model\": \"gemini-2.5-pro\",\n",
    "        \"chunk_size\": 1000,\n",
    "        \"chunk_overlap\": 200,\n",
    "        \"k\": 5,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"\\nEvaluation completed! Check the LangSmith UI for detailed results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2374f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.answer</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.correctness</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why does Anne begin attending church even thou...</td>\n",
       "      <td>I don't know. The context indicates that Anne ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Anne attends church not for the sermon, but fo...</td>\n",
       "      <td>1</td>\n",
       "      <td>298.775518</td>\n",
       "      <td>1419eae8-06e5-4e53-97ac-6652dda62e2e</td>\n",
       "      <td>019adad7-ba8e-7740-833c-cbd45737d96c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does Anne learn the true challenges of wor...</td>\n",
       "      <td>Anne learns the true challenges of gardening w...</td>\n",
       "      <td>None</td>\n",
       "      <td>Anne discovers the real difficulty of gardenin...</td>\n",
       "      <td>1</td>\n",
       "      <td>290.020175</td>\n",
       "      <td>16a9b6b4-6427-4eba-a067-41dc15b72efd</td>\n",
       "      <td>019adadc-6915-752f-9bed-1c0c7f222748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What inner conflict does Anne experience after...</td>\n",
       "      <td>After receiving old Willy's bequest, Anne expe...</td>\n",
       "      <td>None</td>\n",
       "      <td>Anne feels deep self-reproach after Willy's be...</td>\n",
       "      <td>1</td>\n",
       "      <td>290.523999</td>\n",
       "      <td>dee59ebc-2745-4460-8b09-8ec78d016bff</td>\n",
       "      <td>019adae0-f8ec-7149-acf6-b9f8f7fe9aeb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults agenticAIReport-correctness-eval-93ce3a36>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4f06dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "end2end-rag (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
